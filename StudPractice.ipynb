{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StudPractice.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "При необходимости:\n",
        "*   pip install pymorphy2\n",
        "*   nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "BU_EKIB1Xbko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Импортируем нужные иструменты"
      ],
      "metadata": {
        "id": "fQy7cSLlaAxU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VAHoDv8p5Ovy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подгружаем данные"
      ],
      "metadata": {
        "id": "b9BPoImoZ1Uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/positive.csv\", sep = ';', header = None)\n",
        "negative = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/negative.csv\", sep = ';', header = None)\n",
        "full = pd.concat([positive, negative])\n",
        "full = full.drop(full.columns[[0,1,2,5,6,7,8,9,10,11]], axis = 1)\n",
        "\n",
        "full.columns=[\"tweet\", \"tonality\"]"
      ],
      "metadata": {
        "id": "7jBr8dEk5liN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Предобработка данных"
      ],
      "metadata": {
        "id": "XRGPFF-7aJYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "morph = MorphAnalyzer()\n",
        "ru_stopwords = stopwords.words(\"russian\")\n",
        "\n",
        "def preprocessing(text):\n",
        "    text = re.sub(\"[^А-яа-я]\", \" \", text)\n",
        "    result = list()\n",
        "    for word in text.split():\n",
        "      if word and word not in ru_stopwords:\n",
        "        word = morph.parse(word)[0].normal_form\n",
        "        result.append(word)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "fcJAvTOq6RMy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clear_data = full['tweet'].apply(preprocessing)\n",
        "clear_data = pd.concat([clear_data, full[\"tonality\"]], axis = 1)"
      ],
      "metadata": {
        "id": "_Inb6Vbs6SKE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Разделяем на тренировочную и тестовую выборки"
      ],
      "metadata": {
        "id": "YW-3tovTaPNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(clear_data, test_size = 0.2)\n",
        "train.columns = [\"tweet\", \"tonality\"]\n",
        "test.columns = [\"tweet\", \"tonality\"]\n",
        "text_train = train['tweet'].apply(lambda x: \" \".join(x))\n",
        "ton_train = train['tonality']\n",
        "text_test = test['tweet'].apply(lambda x: \" \".join(x))\n",
        "ton_test = test['tonality']"
      ],
      "metadata": {
        "id": "KKnmolGU7wOJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Логистическая регрессия"
      ],
      "metadata": {
        "id": "w97n_mJioBJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression(solver = 'newton-cg')\n",
        "score = [0, 0, 0, 0]"
      ],
      "metadata": {
        "id": "Xnq5mpv4oDqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Н-граммы для BOW"
      ],
      "metadata": {
        "id": "wEB_gugPb2cR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [1,2,3]:\n",
        "  vectorizer = CountVectorizer(ngram_range = (i, i))\n",
        "  text_train_ngram = vectorizer.fit_transform(text_train)\n",
        "  text_test_ngram = vectorizer.transform(text_test)\n",
        "  logreg.fit(text_train_ngram, ton_train)\n",
        "  lr_prediction = logreg.predict(text_test_ngram)\n",
        "  score[i] = f1_score(ton_test, lr_prediction)"
      ],
      "metadata": {
        "id": "hZPJifcKhZku"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF"
      ],
      "metadata": {
        "id": "6pUPDORlnm_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "text_train_tfidf = vectorizer.fit_transform(text_train)\n",
        "text_test_tfidf = vectorizer.transform(text_test)\n",
        "logreg.fit(text_train_tfidf, ton_train)\n",
        "lr_prediction = logreg.predict(text_test_tfidf)\n",
        "score[0] = f1_score(ton_test, lr_prediction)"
      ],
      "metadata": {
        "id": "bVxfAlOznvC0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Результаты"
      ],
      "metadata": {
        "id": "ry3_nt8Rcz_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('TF-IDF\\t\\t\\t1Grams\\t\\t\\t2Grams\\t\\t\\t3Grams')\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9DP68IIc-pA",
        "outputId": "91d7c96a-038d-43ab-dd50-edd01ca59b08"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF\t\t\t1Grams\t\t\t2Grams\t\t\t3Grams\n",
            "[0.7357669193688816, 0.7312112407303005, 0.6880903573294747, 0.2855409648872395]\n"
          ]
        }
      ]
    }
  ]
}